[
    "Unleashing Inﬁnite-Length Input Capacity for Large-scale Language\nModels with Self-Controlled Memory System\nXinnian Liang1∗†, Bing Wang1∗†, Hui Huang3†, Shuangzhi Wu2‡\nPeihao Wu2, Lu Lu2, Zejun Ma2 and Zhoujun Li1‡\n1State Key Lab of Software Development Environment, Beihang University, Beijing, China\n2ByteDance AI Lab, Beijing, China\n3Harbin Institute of Technology, Harbin, China\n{xnliang,bingwang,lizj}@buaa.edu.cn; {wufurui,mazejun}@bytedance.com;\nAbstract\nLarge-scale Language Models (LLMs) are\nconstrained by their inability to process\nlengthy inputs. To address this limitation, we\npropose the Self-Controlled Memory (SCM)\nsystem to unleash inﬁnite-length input capac-\nity for large-scale language models.\nOur\nSCM system is composed of three key mod-\nules: the language model agent, the memory\nstream, and the memory controller. The lan-\nguage model agent iteratively processes ultra-\nlong inputs and stores all historical informa-\ntion in the memory stream.\nThe memory\ncontroller provides the agent with both long-\nterm memory (archived memory) and short-\nterm memory (ﬂash memory) to generate pre-\ncise and coherent responses. The controller de-\ntermines which memories from archived mem-\nory should be activated and how to incorpo-\nrate them into the model input. Our SCM sys-\ntem can be integrated with any LLMs to en-\nable them to process ultra-long texts without\nany modiﬁcation or ﬁne-tuning. Experimen-\ntal results show that our SCM system enables\nLLMs, which are not optimized for multi-turn\ndialogue, to achieve multi-turn dialogue capa-\nbilities that are comparable to ChatGPT, and\nto outperform ChatGPT in scenarios involving\nultra-long document summarization or long-\nterm conversations. Additionally, we will sup-\nply a test set, which covers common long-text\ninput scenarios, for evaluating the abilities of\nLLMs in processing long documents. 12\n1\nIntroduction\nRecently, Large-scale Language Models (LLMs)\nhave attracted signiﬁcant attention due to their\nremarkable performance in a diverse range of\ntasks (Brown et al., 2020a; Zeng et al., 2023;\n*The authors contribute equally and the order is random.\n†Contribution during internship at ByteDance Inc.\n‡Corresponding Author\n1Working in progress.\n2https://github.com/wbbeyourself/SCM4LLMs\n[Our SCM System]:\nBased on our previous\nconversation, your hobbies\ninclude swimming, climbing\nmountains, and traveling. Is\nthere anything related to those\nhobbies that you need assistance\nwith?\n[ChatGPT]:\nAs an AI language model, I don't have\naccess to your personal information or\ninterests, so I can't say for sure what\nyour hobby is. However, I can suggest\nsome common hobbies that people\nenjoy such as reading, writing, painting,\nplaying sports, cooking, gardening,\nplaying musical instruments, and many\nmore. You can explore different hobbies\nand find the one that brings you joy and\nfulfillment.\n[User]: What are your hobbies?\n[System]: As an AI language model, I don't have hobbies like humans do.\nHowever, I am programmed to assist with various tasks and answer\nquestions. Is there anything specific you need help with?\"\n[User]: Tell you my hobby: swimming, climbing mountain and traveling.\n... ... (50+ turns of dialogue about hobby and other topics is omitted here.)\n[User]: We talk about hobbies again. What do you think is my hobby?\nFigure 1: An example comparing ChatGPT and our\nSCM system. The orange text indicates the user’s cur-\nrent question, bold text denotes related historical infor-\nmation, red text indicates an erroneous response from\nChatGPT, and green text denotes the correct response\nfrom our system.\nOuyang et al., 2022; Thoppilan et al., 2022; Work-\nshop et al., 2023; Muennighoff et al., 2022). The\nstrong foundational capability of LLMs, achieved\nthrough large-scale pre-training on massive text\ncorpora (e.g., In-Context Learning (Brown et al.,\n2020a), Chain-of-Thoughts (Wei et al., 2022c,b),\namong others), is a contributing factor to their suc-\ncess. Instruction tuning (Raffel et al., 2020; Wei\net al., 2022a; Chung et al., 2022) helps LLMs com-\nprehend natural language task descriptions, while\nReinforcement Learning with Human Feedback\n(RLHF) (Schulman et al., 2017; Stiennon et al.,\n2020; Bai et al., 2022) aligns generated text with\nhuman preferences. The combined capabilities of\nLLMs have effectively shattered the boundaries\nbetween natural language processing tasks, lead-\ning to limitless possibilities in the application and\nresearch directions of LLMs.\nLarge Language Models (LLMs) offer numerous\nadvantages, but their utility is hindered by two main\nfactors: the maximum input length and the com-\narXiv:2304.13343v1  [cs.CL]  26 Apr 2023\n",
    "putational complexity of self-attention during the\npre-training phase (Wang et al., 2020). Although\nsome models (Press et al., 2022; OpenAI, 2022) are\ncapable of processing long inputs, they may still\nstruggle to capture crucial contextual information\nin exceptionally lengthy texts. As demonstrated in\nFigure 1, even the ChatGPT 3 can miss out on es-\nsential context from preceding text because of the\naccumulation of historical noise, which refers to\nirrelevant or outdated information that can hinder\ncomprehension.\nTo address this limitation, we present the Self-\nControlled Memory (SCM) system, which enables\nLarge Language Models (LLMs) to process text\nof inﬁnite length without any modiﬁcation or ad-\nditional training. The input is partitioned into seg-\nments and fed to the LLM as observations (inputs).\nThe SCM expands the LLM with a long-term mem-\nory (archived memory), a short-term memory (ﬂash\nmemory), and a memory controller. The archived\nmemory preserves all historical information, while\nthe ﬂash memory captures real-time memory in-\nformation from previous rounds.\nThe memory\ncontroller determines when and how to introduce\narchived information, allowing the LLM to efﬁ-\nciently handle ultra-long text without sacriﬁcing\nany essential information.\nTo evaluate the performance of our system, we\nintegrate the SCM with non-dialogue-optimized\nLLMs and simulate ChatGPT with success. Our\nﬁndings indicate that our system outperforms Chat-\nGPT in handling ultra-long inputs or conversations.\nFor summarization tasks, we generate a hierarchi-\ncal summary of the entire archived memory un-\ntil the summary length meets the user’s speciﬁca-\ntions. By incorporating information from preced-\ning text into local summaries within the memory,\nour approach preserves the correlations among the\noriginal content, in contrast to the conventional\napproach of directly generating a hierarchical sum-\nmary of the entire text. Furthermore, our work is\nstill in progress, and we plan to release a compre-\nhensive evaluation dataset designed for long-text\ntasks, along with standardized human evaluations\nto evaluate the effectiveness of different methods.\n2\nRelated Work\nLarge-scale\nLanguage\nModels.\nLarge-scale\nLanguage Models (LLMs) are language models\ntrained on massive amounts of text data, using the\n3In this study, we utilize OpenAI gpt-3.5-turbo-0301.\nTransformer (Vaswani et al., 2017) architecture as\ntheir foundation. The earliest Transformer-based\npre-trained language model was GPT-1 (Radford\net al., 2018). Subsequently, GPT-2 (Radford et al.,\n2019) and GPT-3 (Brown et al., 2020b) were de-\nveloped with gradually increasing parameter sizes.\nGPT-3 has the largest scale, with 175B parameters,\nalong with emergent abilities (Wei et al., 2022b,c),\nwhich has attracted the attention of both academia\nand industry.\nSince then, many LLMs have emerged, including\nLAMBDA (Thoppilan et al., 2022), PaLM (Chowd-\nhery et al., 2022), OPT (Zhang et al., 2022a),\nLLaMA (Touvron et al., 2023), BLOOM (Work-\nshop et al., 2023), Galactica (Taylor et al., 2022),\nand Pangu (Zeng et al., 2021; Ren et al., 2023). One\nof the most notable works in this series of research\nthat has attracted widespread industry attention and\ncan be considered a milestone towards Artiﬁcial\nGeneral Intelligence (AGI) is ChatGPT (OpenAI,\n2022), which is based on InsctuctGPT (Ouyang\net al., 2022) and optimized for multi-turn dialogue\nability. ChatGPT has achieved remarkable perfor-\nmance and surpassed the boundaries between NLP\ntasks. However, current LLMs, including ChatGPT,\nface signiﬁcant limitations when processing tasks\ninvolving extremely long inputs.\nLong Text Sequence Processing.\nHandling long\ntext sequences has been a persistent challenge in\nnatural language processing tasks. This problem\nhas become even more prominent with the advent\nof pre-training and LLMs, as the ﬁxed input length\nduring pre-training and the high costs of expanding\nit during the pre-training stage limit the ability to\nprocess longer inputs. Existing solutions primar-\nily involve replacing the Attention structure during\npre-training to reduce computational costs and ex-\npanding the pre-training sequence length (Beltagy\net al., 2020; Zaheer et al., 2021; Guo et al., 2022;\nPhang et al., 2022; Dong et al., 2023). Another al-\nternative approach (Press et al., 2022) uses special\npositional encoding during pre-training to enable\nthe model to learn relative positions and handle\nlonger input texts during inference.\nHowever, the generalizability of these methods\nand their impact on downstream tasks remain uncer-\ntain. In the ﬁeld of long-text summarization, there\nare many effective methods. Hierarchical or itera-\ntive methods have been used by Wu et al. (2021);\nZhang et al. (2022b); Cao and Wang (2022) to\nhandle long texts by decomposing a complex prob-\n",
    "Summarize all previous\nsolutions for ... \nMemory\nStream\nActivation\nMemory\nYou can solve it\nas follows:1. xx\n2. xx ... ...\nFlash\nMemory\nArchived\nMemory\nMemory\nController\n(Memory From #T-1)\nNew Memory\n1\n2\n3\n4\n5\n6\nAgent\nResponse #T\nObservation #T\nFigure 2: The workﬂow of our proposed Self-Controlled Memory(SCM) system, where numbers 1-6 represent the\nsequential process of one iteration with new observation #T.\nlem into multiple sub-problems. However, these\nmethods fail to capture the relationships among\nsub-problems.\n3\nMethodology\nThe Self-Controlled Memory (SCM) system pro-\nposed in this paper aims to give large-scale lan-\nguage models (LLMs) the capability to store long-\nterm memories, allowing them to process lengthy\ninputs and retain information after multiple interac-\ntions with the user.\n3.1\nSystem Overview\nIn this section, we introduce the workﬂow of our\nproposed SCM system. As illustrated in Figure 2,\nour SCM system comprises three modules, includ-\ning a language model agent, a memory stream, and\na memory controller. The three modules work to-\ngether to process lengthy documents and provide\nmore accurate and coherent responses. Our system\nworkﬂow consists of six explicit steps, which are\npresented as follows:\n1. Input Acquisition: The agent receives an ob-\nservation in turn T (i.e., ultra-long document input\nor a user question), either through direct input or\nfrom an external source.\n2. Memory Activation: Based on the current\nobservation, the memory controller determines\nwhether it is necessary to activate memory for the\ncurrent user input. In the case where memory acti-\nvation is warranted, relevant memories (for detailed\nmemory information, refer to section § 3.2) is re-\ntrieved by executing steps 3 and 4. Otherwise, the\nprocess moves directly to step 5. § 3.3.1 provides a\ncomprehensive explanation of the control ﬂow of\nthe memory controller.\n3. Memory Retrieval: In this step, we utilize the\nobservation as a query to identify related memories.\nThe score ranking of each memory is computed\nby considering two dimensions: relevance and re-\ncency. With respect to relevance, we evaluate how\nsimilar the content of the memory is to the observa-\ntion. With respect to recency, we consider the time\nelapsed since the memory was last accessed. Sub-\nsequently, we retain the top K-ranked memories.\n4. Memory Reorganization: In this step, the con-\ntroller will determine whether to use the original\nmemory directly or the summarized memory. If\nsummarized memory is chosen, the original mem-\nory the will be compressed. § 3.3.2 provides a\ndetailed explanation of the state compression pro-\ncess. Then, the system will combine the memory\nretrieved in a structured manner to serve as back-\nground information for response generation at this\npoint.\n5. Input Fusion: In this step, we carefully de-\nsign a prompt that fuses the restructured memory\nwith the present observation to serve as the model’s\ninput. A thorough description is given in § 3.4.\n6. Response Generation: The model generates a\nresponse based on previous step result and incorpo-\nrates the current interaction, including observation\n",
    "Is memory retrieval necessary?\nSummary or Full Content?\nRetrieve From Archived Memory\nY/N\nSummarize Activated Content\nY/N\nFull Contnet\nSummary\nGenerator\nController\nObservation\nNO\nNO\nMemory Controller\nFigure 3: Workﬂow of the Memory Controller.\nand response, into the memory stream. Please refer\nto § 3.4 for further details.\n3.2\nMemory Stream\nThis section provides an overview of the internal\nstructure of memory stream. The memory stream\nstores all historical memory items in a designated\nlocation named as the archived memory center,\nwhich can easily achieve high-speed access through\ncache storage and access tools such as Redis or\nPinecone4. Each memory item consists of an in-\nteraction index, an observation, a system response,\nand an interaction embedding that illustrates the\ncurrent interaction semantics. In addition, The Ac-\ntivation Memory stores the retrieved memory set,\nand the Flash Memory indicates the memory of\nTurn T − 1.\n3.3\nMemory Controller\nThis section discusses the reasons for using the\nmemory controller and its workﬂow, as illustrated\nin Figure 3. There exist three fundamental reasons.\nFirstly, not all observations, also referred to as user\ninput or instruction, require access to historical\nmemory usage. For example, the user instruction\n“Tell me a joke” does not require the retrieval of\nthe user’s history memory. However, certain user\ninput such as “Do you remember the conclusion we\nmade last week on the ﬁtness diets” requires retriev-\ning past memories. The second reason is that the\namount of memory can be enormous, ranging from\n4Pinecone: https://www.pinecone.io/\nGiven a user command, determine whether executing the\ncommand requires historical or previous information, or\nwhether it requires recalling the conversation content.\nSimply answer yes (A) or no (B) without explaining the\ninformation:\nCommand: [User Input]\nFigure 4: English prompt for the necessity of using\nmemory.\nGiven a user command, determine if it can be executed\ncorrectly based solely on the summary historical\ninformation provided. Simply answer yes (A) or no (B),\nwithout explaining the information.\nCommand: [User Input]\nFigure 5: English prompt for whether or not to use the\nsummary of memory.\nhundreds to thousands or even tens of thousands. A\ncontroller is needed to retrieve and ﬁlter the mem-\nory. The third reason is that the input length of\nthe model is limited, and a controller is needed to\nchoose between using the full text of the memory\nor a summary of the memory, as the original text\ncan be long and may exceed the maximum length\nof the model. The next two subsections present\nthe details of the controller’s workﬂow and state\ncompression implementation, respectively.\n3.3.1\nMemory Controller Workﬂow\nThe core of the controller in terms of process con-\ntrol is to ask two questions of the agent:\n1. Is it necessary to use memory to accurately\nanswer when executing user commands?\n2. Can user commands be executed normally us-\ning only the summary of memory?\nThe ﬁrst question prompt is shown in Figure 4,\nwhile the prompt for the second question is shown\nin Figure 5. Other language versions of the prompt\ncan be found in § A.1.\nIf the controller determines the necessity of uti-\nlizing historical memory, memory retrieval should\nbe carried out. While retrieving memories, we use\nthe current observation (i.e. user instruction) as\na query and evaluate each memory’s rank score\nbased on two factors: Recency and Relevance. Re-\ncency highly prioritizes memory items accessed\n",
    "Below is a conversation between a user and an AI\nassistant. Please provide a summary of the user's\nquestion and the assistant's response in one\nsentence each, with separate paragraphs, while\npreserving key information as much as possible.\nConversation: \nUser: [user input]\nAssistant: [system response]\nSummary:\nFigure 6: Prompt for dialogue memory summarization.\nrecently, reinforcing the idea that the agent’s atten-\ntion remains on the states of latest interactions. The\nrelevance factor assigns a higher score to memory\nitems that are related to the current observation.\nIn our implementation, we created an embedding\nvector for the text description of every memory\nthrough the use of a language model5. The co-\nsine similarity between the embedding vector of\nthe memory and that of the query observation is\ncalculated to determine relevance. The rank score\nof each memory is the sum of its recency and rel-\nevance scores: rank_score = recency_score +\nrelevance_score. Depending on the length limit,\nwe designate the top k memories with the highest\nrank scores as activated memories, where k varies\nbetween 3 and 10.\nIf the controller determines that the employment\nof a summary can allow for the normal execution\nof instructions, then it is necessary to summarize\nthe current extracted memories. The speciﬁc in-\nformation regarding the memory summarization is\nlocated in the following subsection.\n3.3.2\nMemory Summarization\nMemory summarization is a crucial aspect in sce-\nnarios such as document summarization, where a\nsingle interaction or dialogue turn can have a token\nlength exceeding 3000. It enables stacking multiple\nmemories into an activated memory section. Fig-\nure 6 shows the English prompt that is speciﬁcally\ndesigned for memory summarization in individual\ninteractions (i.e., dialogue tasks). In addition, other\nlanguage versions of the prompt can be found in\n§ A.3.\n5We used OpenAI embedding model text-embedding-ada-\n002\nHere is a conversation between a user and an AI\nassistant. Please answer the user's current\nquestion based on the history of the conversation:\nHistory of the conversation:\n[History of Related Turn]\nPrevious conversation:\n    \nUser: [previous user input]\nAssistant: [previous system response]\n###\nUser: [current user input]\nAssistant:\nFigure 7: English Prompt of ultra-long dialogue gener-\nation.\n3.4\nResponse Generation\nAs mentioned in the introduction, SCM allows non-\ndialogue-optimized LLMs to emulate ChatGPT.\nThis necessitates providing explicit instructions to\nprompt LLMs to use activated and ﬂash memory to\ngenerate the desired response. Figure 7 shows an\nEnglish prompt intended for extremely long multi-\ninteraction dialogues, with other language versions\nincluded in the § A.2.\n4\nExperiments\n4.1\nSettings\nOur framework is preliminarily evaluated in two\nscenarios: ultra-long dialogues and ultra-long doc-\nument summarization. We conduct experiments to\nanswer three research questions (RQs).\n• RQ1. Can SCM system compete with or even\noutperform ChatGPT within a speciﬁc token\nlimit?\n• RQ2. Can SCM system scale to provide ac-\ncurate responses to users’ questions, which are\nrelated to historical contexts that date back hun-\ndreds or even thousands of turns?\n• RQ3. Can SCM demonstrate generalization to\nother scenarios, including long document sum-\nmarization?\nThe following experiment evaluates the perfor-\nmance of the text-davinci-003 model without dia-\n",
    "... after 10 days and 500+ turns of dialogue\nThat's a great goal! I can help you reach your goal weight. What kind of exercise plan do you have in mind?\nI’m planning to exercise more regularly, starting with running.\nThat's a great start! How often do you plan to run?\nI’m aiming to work out three times a week.\nIt sounds like you have a great plan! To help you stay motivated, why don't you set goals for each session? \nI’ve got some good news to share - my weight loss has been going well lately and I’m down to 68kg now.\nCongratulations! That's great news. What have you been doing to help you reach this goal?\nIt’s because I’ve recently started enjoying sports like swimming and basketball again.\nThat's wonderful! It's great that you're finding activities that you enjoy and can stick with.\nYes, you mentioned that you wanted to start running as your first sport. Are you still running?\nDo you remember my first sport?\nI feel like I’ve gained weight recently and I’m planning to lose some. My goal weight is 65 kilograms.\nFigure 8: Ultra-long dialogue example.\nlogue optimization in comparison to the ChatGPT-\nTurbo model. The evaluation focuses on the tasks\nof ultra-long dialogues and ultra-long document\nsummarization.\n4.2\nQualitative Study\nRQ1. Can SCM system compete with or even\noutperform ChatGPT within a speciﬁc token\nlimit? Yes.\nThe example in Figure 1 includes 4000 tokens,\nwherein the user inquired about their hobbies, dis-\ncussed 100+ turns ago with the agent. The SCM\nsystem provides an accurate response to the query,\ndemonstrating exceptional memory-enhanced ca-\npabilities, as apparent from the observation. In\ncontrast, it appears that ChatGPT was distracted by\na considerable amount of irrelevant historical data.\nRQ2. Can SCM system scale to provide accu-\nrate responses to users’ questions, which are\nrelated to historical contexts that date back\nhundreds or even thousands of turns? Yes.\nThe example presented in Figure 8 illustrates\na ultra-long dialogue comprising over 500 turns.\nAt the outset, the user states that his goal is to\nreduce weight and intends to initiate a running\nregime. Subsequently, the user and the model con-\nverse daily about progress towards achieving their\nweight loss goals, among other conversation topics.\nAfter ten days, the length of the dialogue reaches\n10,000 tokens. The user then asks the model “Do\nyou remember my ﬁr”. Our SCM system accurately\nresponds to this question.\nRQ3. Can SCM demonstrate generalization\nto other scenarios, including long document\nsummarization? Yes.\nFigure 9 illustrates an instance of an incredibly\nlengthy document summary. Speciﬁcally, the re-\nport pertains to the unveiling of GPT-4 by OpenAI.\nSummaries exceeding 4,000 characters pose a chal-\nlenge for conventional models, thus necessitating\nthe splitting and individual summarization of doc-\nument parts, which are then united. Nonetheless,\nthis method can lose the dependency relationship\nbetween paragraphs. Our framework utilizes a it-\nerative summarization procedure. While summa-\nrizing paragraphs, our approach relies on earlier\nrelevant summary memories to generate more pre-\ncise summaries. Ultimately, the framework incor-\nporates a divide-and-conquer strategy to generate\nthe ﬁnal document summary. The ﬁnal summary\nobtained through the divide-and-conquer method\nprovides a comprehensive summary by utilizing\ninformation from each document block. Further-\nmore, our iterative summary paradigm contains\na memory-enhancement feature that allows topic-\nspeciﬁc summaries to be generated by integrating a\n",
    "Figure 9: Ultra-long iterative and hierarchical summarization example.\nquestion-asking methodology during single block\nsummarization. For instance, if a user poses a\nquestion such as \"Please provide a summary of the\ntechnical details and evaluation ﬁndings of GPT4\nin image processing\", the model will access prior\nsummary memories and extract the relevant con-\ntent. We will continue to improve this aspect in the\nfuture.\n5\nLimitations and Risks\nLimitations\nA lack of appropriate datasets for\nevaluating the handling of extremely lengthy texts\nhas resulted in our model being validated solely\nthrough manual veriﬁcation. This method, how-\never, is inadequate for evaluating different scenar-\nios comprehensively and objectively. Therefore,\nwe aim to construct a speciﬁc test set that incorpo-\nrates various key indicators essential for processing\nlong texts in diverse settings. This test set will be\naccompanied by a manual evaluation standard to\nenable a more equitable comparison with relevant\nmethods. Moreover, we will assess the efﬁcacy\nof our system on more open-source models that\npossess single-turn instruction comprehension ca-\npability.\nRisks\nOur system has the capability to attach to\nany LLMs, which may be prone to factual errors,\ndelusions, toxic language, and malicious responses.\nConsequently, we restrict the usage of our system\nto academic research purposes for now.\n6\nConclusion and Future Work\nIn this paper, we propose a Self-Controlled Mem-\nory (SCM) system to extend the input length of any\nLLMs model to an unlimited length and effectively\ncapture useful information from all historical infor-\nmation. This method does not require any training\nor modiﬁcation of models and has strong applicabil-\nity. We validated the effectiveness of our method\nthrough manual evaluation of the ChatGPT and\nthe Text-DaVinci-003 model based on our system,\ndemonstrating superior performance in certain as-\npects of long-text scenarios compared to ChatGPT.\nOur future work will focus on releasing a com-\nprehensive test set and its manual evaluation crite-\nria, and testing our system on various open-source\nmodels currently available.\nReferences\nYuntao Bai, Andy Jones, Kamal Ndousse, Amanda\nAskell, Anna Chen, Nova DasSarma, Dawn Drain,\nStanislav Fort,\nDeep Ganguli,\nTom Henighan,\nNicholas\nJoseph,\nSaurav\nKadavath,\nJackson\nKernion, Tom Conerly, Sheer El-Showk, Nelson\nElhage, Zac Hatﬁeld-Dodds, Danny Hernandez,\nTristan Hume, Scott Johnston, Shauna Kravec,\n",
    "Liane Lovitt, Neel Nanda, Catherine Olsson, Dario\nAmodei, Tom Brown, Jack Clark, Sam McCandlish,\nChris Olah, Ben Mann, and Jared Kaplan. 2022.\nTraining a helpful and harmless assistant with\nreinforcement learning from human feedback.\nIz Beltagy, Matthew E. Peters, and Arman Cohan. 2020.\nLongformer: The long-document transformer.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell,\nSandhini Agarwal,\nAriel Herbert-Voss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen,\nEric Sigler, Mateusz Litwin, Scott Gray, Benjamin\nChess, Jack Clark, Christopher Berner, Sam Mc-\nCandlish, Alec Radford, Ilya Sutskever, and Dario\nAmodei. 2020a.\nLanguage models are few-shot\nlearners.\nIn Advances in Neural Information Pro-\ncessing Systems 33: Annual Conference on Neu-\nral Information Processing Systems 2020, NeurIPS\n2020, December 6-12, 2020, virtual.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell,\nSandhini Agarwal,\nAriel Herbert-Voss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen,\nEric Sigler, Mateusz Litwin, Scott Gray, Benjamin\nChess, Jack Clark, Christopher Berner, Sam Mc-\nCandlish, Alec Radford, Ilya Sutskever, and Dario\nAmodei. 2020b.\nLanguage models are few-shot\nlearners.\nShuyang Cao and Lu Wang. 2022. HIBRIDS: Atten-\ntion with hierarchical biases for structure-aware long\ndocument summarization.\nIn Proceedings of the\n60th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n786–807, Dublin, Ireland. Association for Computa-\ntional Linguistics.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\nRao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben\nHutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng\nYin, Toju Duke, Anselm Levskaya, Sanjay Ghe-\nmawat, Sunipa Dev, Henryk Michalewski, Xavier\nGarcia, Vedant Misra, Kevin Robinson, Liam Fe-\ndus, Denny Zhou, Daphne Ippolito, David Luan,\nHyeontaek Lim, Barret Zoph, Alexander Spiridonov,\nRyan Sepassi, David Dohan, Shivani Agrawal, Mark\nOmernick, Andrew M. Dai, Thanumalayan Sankara-\nnarayana Pillai, Marie Pellat, Aitor Lewkowycz,\nErica Moreira, Rewon Child, Oleksandr Polozov,\nKatherine Lee, Zongwei Zhou, Xuezhi Wang, Bren-\nnan Saeta, Mark Diaz, Orhan Firat, Michele Catasta,\nJason Wei, Kathy Meier-Hellstern, Douglas Eck,\nJeff Dean, Slav Petrov, and Noah Fiedel. 2022.\nPalm: Scaling language modeling with pathways.\nHyung Won Chung, Le Hou, Shayne Longpre, Barret\nZoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma, Al-\nbert Webson, Shixiang Shane Gu, Zhuyun Dai,\nMirac Suzgun, Xinyun Chen, Aakanksha Chowdh-\nery, Alex Castro-Ros, Marie Pellat, Kevin Robin-\nson, Dasha Valter, Sharan Narang, Gaurav Mishra,\nAdams Yu, Vincent Zhao, Yanping Huang, Andrew\nDai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean,\nJacob Devlin, Adam Roberts, Denny Zhou, Quoc V.\nLe, and Jason Wei. 2022.\nScaling instruction-\nﬁnetuned language models.\nChenhe Dong, Yinghui Li, Haifan Gong, Miaoxin\nChen, Junxin Li, Ying Shen, and Min Yang. 2023.\nA survey of natural language generation. ACM Com-\nput. Surv., 55(8):173:1–173:38.\nMandy Guo, Joshua Ainslie, David Uthus, Santiago\nOntanon, Jianmo Ni, Yun-Hsuan Sung, and Yinfei\nYang. 2022.\nLongT5: Efﬁcient text-to-text trans-\nformer for long sequences. In Findings of the Associ-\nation for Computational Linguistics: NAACL 2022,\npages 724–736, Seattle, United States. Association\nfor Computational Linguistics.\nNiklas Muennighoff, Thomas Wang, Lintang Sutawika,\nAdam Roberts, Stella Biderman, Teven Le Scao,\nM Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hai-\nley Schoelkopf, Xiangru Tang, Dragomir Radev, Al-\nham Fikri Aji, Khalid Almubarak, Samuel Albanie,\nZaid Alyafeai, Albert Webson, Edward Raff, and\nColin Raffel. 2022.\nCrosslingual generalization\nthrough multitask ﬁnetuning.\nOpenAI. 2022. Introducing chatgpt.\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida,\nCarroll L. Wainwright, Pamela Mishkin, Chong\nZhang, Sandhini Agarwal, Katarina Slama, Alex\nRay, John Schulman, Jacob Hilton, Fraser Kelton,\nLuke Miller, Maddie Simens, Amanda Askell, Pe-\nter Welinder, Paul Christiano, Jan Leike, and Ryan\nLowe. 2022. Training language models to follow in-\nstructions with human feedback.\nJason Phang, Yao Zhao, and Peter J. Liu. 2022. Inves-\ntigating efﬁciently extending transformers for long\ninput summarization.\nOﬁr Press, Noah Smith, and Mike Lewis. 2022. Train\nshort, test long: Attention with linear biases enables\ninput length extrapolation. In International Confer-\nence on Learning Representations.\nAlec Radford, Jeff Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2018. Improving\nlanguage understanding with unsupervised learning.\n",
    "Alec Radford, Jeff Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners.\nColin Raffel, Noam Shazeer, Adam Roberts, Kather-\nine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2020.\nExploring\nthe limits of transfer learning with a uniﬁed text-to-\ntext transformer. Journal of Machine Learning Re-\nsearch, 21(140):1–67.\nXiaozhe Ren, Pingyi Zhou, Xinfan Meng, Xinjing\nHuang, Yadao Wang, Weichao Wang, Pengfei Li,\nXiaoda Zhang, Alexander Podolskiy, Grigory Arshi-\nnov, Andrey Bout, Irina Piontkovskaya, Jiansheng\nWei, Xin Jiang, Teng Su, Qun Liu, and Jun Yao.\n2023.\nPangu-Σ: Towards trillion parameter lan-\nguage model with sparse heterogeneous computing.\nJohn Schulman, Filip Wolski, Prafulla Dhariwal, Alec\nRadford, and Oleg Klimov. 2017. Proximal policy\noptimization algorithms.\nNisan Stiennon, Long Ouyang, Jeff Wu, Daniel M.\nZiegler, Ryan Lowe, Chelsea Voss, Alec Radford,\nDario Amodei, and Paul F. Christiano. 2020. Learn-\ning to summarize from human feedback.\nCoRR,\nabs/2009.01325.\nRoss\nTaylor,\nMarcin\nKardas,\nGuillem\nCucurull,\nThomas Scialom, Anthony Hartshorn, Elvis Saravia,\nAndrew Poulton, Viktor Kerkez, and Robert Stojnic.\n2022. Galactica: A large language model for sci-\nence.\nRomal Thoppilan, Daniel De Freitas, Jamie Hall,\nNoam Shazeer, Apoorv Kulshreshtha, Heng-Tze\nCheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,\nYaGuang Li, Hongrae Lee, Huaixiu Steven Zheng,\nAmin Ghafouri, Marcelo Menegali, Yanping Huang,\nMaxim Krikun, Dmitry Lepikhin, James Qin, De-\nhao Chen, Yuanzhong Xu, Zhifeng Chen, Adam\nRoberts, Maarten Bosma, Vincent Zhao, and etc.\n2022. Lamda: Language models for dialog appli-\ncations.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro,\nFaisal Azhar, Aurelien Rodriguez, Armand Joulin,\nEdouard Grave,\nand Guillaume Lample. 2023.\nLlama: Open and efﬁcient foundation language mod-\nels.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems, volume 30. Curran Associates, Inc.\nSinong Wang, Belinda Z. Li, Madian Khabsa, Han\nFang, and Hao Ma. 2020. Linformer: Self-attention\nwith linear complexity.\nJason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu,\nAdams Wei Yu, Brian Lester, Nan Du, Andrew M.\nDai, and Quoc V Le. 2022a.\nFinetuned language\nmodels are zero-shot learners. In International Con-\nference on Learning Representations.\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raf-\nfel, Barret Zoph, Sebastian Borgeaud, Dani Yo-\ngatama, Maarten Bosma, Denny Zhou, Donald Met-\nzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals,\nPercy Liang, Jeff Dean, and William Fedus. 2022b.\nEmergent abilities of large language models. Trans-\nactions on Machine Learning Research. Survey Cer-\ntiﬁcation.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V\nLe, and Denny Zhou. 2022c.\nChain of thought\nprompting elicits reasoning in large language mod-\nels. In Advances in Neural Information Processing\nSystems.\nBigScience Workshop, :, Teven Le Scao, Angela Fan,\nChristopher Akiki, Ellie Pavlick, Suzana Ili´c, Daniel\nHesslow, Roman Castagné, Alexandra Sasha Luc-\ncioni, François Yvon, Matthias Gallé, Jonathan Tow,\nAlexander M. Rush, and etc. 2023.\nBloom: A\n176b-parameter open-access multilingual language\nmodel.\nJeff Wu, Long Ouyang, Daniel M. Ziegler, Nisan Sti-\nennon, Ryan Lowe, Jan Leike, and Paul Christiano.\n2021. Recursively summarizing books with human\nfeedback.\nManzil Zaheer, Guru Guruganesh, Avinava Dubey,\nJoshua Ainslie, Chris Alberti, Santiago Ontanon,\nPhilip Pham, Anirudh Ravula, Qifan Wang, Li Yang,\nand Amr Ahmed. 2021. Big bird: Transformers for\nlonger sequences.\nAohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang,\nHanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu,\nWendi Zheng, Xiao Xia, Weng Lam Tam, Zix-\nuan Ma, Yufei Xue, Jidong Zhai, Wenguang Chen,\nZhiyuan Liu, Peng Zhang, Yuxiao Dong, and Jie\nTang. 2023.\nGLM-130b: An open bilingual pre-\ntrained model. In The Eleventh International Con-\nference on Learning Representations (ICLR).\nWei Zeng,\nXiaozhe Ren,\nTeng Su,\nHui Wang,\nYi Liao, Zhiwei Wang, Xin Jiang, ZhenZhang\nYang, Kaisheng Wang, Xiaoda Zhang, Chen Li,\nZiyan Gong, Yifan Yao, Xinjing Huang, Jun Wang,\nJianfeng Yu, Qi Guo, Yue Yu, Yan Zhang, Jin\nWang, Hengtao Tao, Dasen Yan, Zexuan Yi, Fang\nPeng, Fangqing Jiang, Han Zhang, Lingfeng Deng,\nYehong Zhang, Zhe Lin, Chao Zhang, Shaojie\nZhang, Mingyue Guo, Shanzhi Gu, Gaojun Fan,\nYaowei Wang, Xuefeng Jin, Qun Liu, and Yonghong\nTian. 2021.\nPangu-α:\nLarge-scale autoregres-\nsive pretrained chinese language models with auto-\nparallel computation.\n",
    "Susan Zhang, Stephen Roller, Naman Goyal, Mikel\nArtetxe, Moya Chen, Shuohui Chen, Christopher De-\nwan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mi-\nhaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel\nSimig, Punit Singh Koura, Anjali Sridhar, Tianlu\nWang, and Luke Zettlemoyer. 2022a. Opt: Open pre-\ntrained transformer language models.\nYusen Zhang, Ansong Ni, Ziming Mao, Chen Henry\nWu, Chenguang Zhu, Budhaditya Deb, Ahmed\nAwadallah, Dragomir Radev, and Rui Zhang. 2022b.\nSummn: A multi-stage summarization framework\nfor long input dialogues and documents. In Proceed-\nings of the 60th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Pa-\npers), pages 1592–1604, Dublin, Ireland. Associa-\ntion for Computational Linguistics.\nA\nPrompt List\nA.1\nPrompt For Memory Controller\n给定一个用户指令，判断执行该指令是否需要历史信\n息或者上文的信息，或者需要回忆对话内容，只需要\n回答是(A)或者否(B)，不需要解释信息：\n指令：[用户输入]\nFigure 10: Chinese Prompt of memory controller.\nA.2\nPrompt for Dialogue Generation\n以下是用户和人工智能助手的对话，请根据历史\n对话内容，回答用户当前问题：\n相关历史对话：\n[历史轮对话内容]\n上一轮对话：\n[上一轮对话内容]\n###\n用户：[用户问题]\n助手：\nFigure 11: Chinese Prompt of ultra-long dialogue gen-\neration.\nA.3\nPrompt for Dialogue State Compression\n以下是用户和人工智能助手的一段对话，请分\n别用一句话写出用户摘要、助手摘要，分段列\n出，要求尽可能保留用户问题和助手回答的关\n键信息。\n对话内容： \n用户：[用户输入]\n助手：[系统回复]\n摘要：\nFigure 12: Chinese Prompt of ultra-long dialogue sum-\nmarization.\n"
]